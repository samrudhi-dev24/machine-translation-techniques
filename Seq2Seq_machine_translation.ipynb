{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq machine translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jR2isJaD-UmM662CEE22MPNjxAD77AWK",
      "authorship_tag": "ABX9TyPyOrw0Akb0IiIQPCyIaynw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samrudhi93/Machine-Translation-techniques/blob/main/Seq2Seq_machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Ti52Lg7uXD",
        "outputId": "cd815f12-2392-4103-f17a-2497dd5e7fce"
      },
      "source": [
        "!wget /content/drive/MyDrive/Colab_Notebooks/fra.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/fra.txt: Scheme missing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "sU4V0wujo5uR",
        "outputId": "9cb960e9-192b-4adf-a7d3-c153ed29fca2"
      },
      "source": [
        "filename = '/content/drive/MyDrive/Colab_Notebooks/fra.txt'\n",
        "txt_file = open(filename, 'r')\n",
        "FileContent = txt_file.read(300)\n",
        "FileContent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\\nGo.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)\\nGo.\\tBouge !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)\\nHi.\\tSalut !\\tCC-BY 2.0 ('"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5TAxFxIADpE"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcejo4DQ8QJZ"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Input, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JJ5KSEpDfuK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx0KUJogDr-y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a32dafd9-42ae-42f3-a540-59dc8b3c23be"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 100\n",
        "latent_dim = 256\n",
        "num_samples = 10000\n",
        "FileContent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\\nGo.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)\\nGo.\\tBouge !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)\\nHi.\\tSalut !\\tCC-BY 2.0 ('"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcCwD13_zDfH"
      },
      "source": [
        "#### Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuOAdhrr61uz"
      },
      "source": [
        "with open('/content/drive/My Drive/Colab_Notebooks/fra.txt', 'r') as f:\n",
        "  lines = f.read().split(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13nwWo8H7SOx"
      },
      "source": [
        "lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohdv-Vm0_GY-",
        "outputId": "ee64b678-8509-4cb5-d413-ab10c654fc0c"
      },
      "source": [
        "\n",
        "#vectorise the data\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open('/content/drive/My Drive/Colab_Notebooks/fra.txt', 'r', encoding='utf-8') as f:\n",
        "  lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")  # /t is used 2 times so for that we use '_' to split it and we get input and targets \n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    #print(input_text)\n",
        "    for char in input_text:\n",
        "      if char not in input_characters:\n",
        "        input_characters.add(char)\n",
        "    for char in target_text:\n",
        "      if char not in target_characters:\n",
        "        target_characters.add(char)\n",
        "#Storing unique characters present in the text \n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "\n",
        "\n",
        "#Now to get the sequnece length of the text we take the max of it. the length of text is from 11 to 15. so here it take max of it which is 15\n",
        "max_encoder_sequence_length = max([len(txt) for txt in input_texts]) \n",
        "max_decoder_sequence_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_sequence_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_sequence_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 92\n",
            "Max sequence length for inputs: 15\n",
            "Max sequence length for outputs: 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLEbn_rWchvI"
      },
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "print(num_encoder_tokens)\n",
        "input_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzIL7hxiQwed",
        "outputId": "7d5057ef-84df-4128-f459-3e763095474e"
      },
      "source": [
        "input_token_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '\"': 2,\n",
              " '$': 3,\n",
              " '%': 4,\n",
              " '&': 5,\n",
              " \"'\": 6,\n",
              " ',': 7,\n",
              " '-': 8,\n",
              " '.': 9,\n",
              " '0': 10,\n",
              " '1': 11,\n",
              " '2': 12,\n",
              " '3': 13,\n",
              " '5': 14,\n",
              " '7': 15,\n",
              " '8': 16,\n",
              " '9': 17,\n",
              " ':': 18,\n",
              " '?': 19,\n",
              " 'A': 20,\n",
              " 'B': 21,\n",
              " 'C': 22,\n",
              " 'D': 23,\n",
              " 'E': 24,\n",
              " 'F': 25,\n",
              " 'G': 26,\n",
              " 'H': 27,\n",
              " 'I': 28,\n",
              " 'J': 29,\n",
              " 'K': 30,\n",
              " 'L': 31,\n",
              " 'M': 32,\n",
              " 'N': 33,\n",
              " 'O': 34,\n",
              " 'P': 35,\n",
              " 'Q': 36,\n",
              " 'R': 37,\n",
              " 'S': 38,\n",
              " 'T': 39,\n",
              " 'U': 40,\n",
              " 'V': 41,\n",
              " 'W': 42,\n",
              " 'Y': 43,\n",
              " 'a': 44,\n",
              " 'b': 45,\n",
              " 'c': 46,\n",
              " 'd': 47,\n",
              " 'e': 48,\n",
              " 'f': 49,\n",
              " 'g': 50,\n",
              " 'h': 51,\n",
              " 'i': 52,\n",
              " 'j': 53,\n",
              " 'k': 54,\n",
              " 'l': 55,\n",
              " 'm': 56,\n",
              " 'n': 57,\n",
              " 'o': 58,\n",
              " 'p': 59,\n",
              " 'q': 60,\n",
              " 'r': 61,\n",
              " 's': 62,\n",
              " 't': 63,\n",
              " 'u': 64,\n",
              " 'v': 65,\n",
              " 'w': 66,\n",
              " 'x': 67,\n",
              " 'y': 68,\n",
              " 'z': 69,\n",
              " 'é': 70}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wugcidpsRPH2"
      },
      "source": [
        "### Data that goes into encoder decoder layer in array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Qi-U2BRJHK"
      },
      "source": [
        "#Taking array of 0's and after that fillig it as per the arguments.\n",
        "#MAking the structure of the array of encoder and decoder layer\n",
        "\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_sequence_length, num_encoder_tokens), dtype=\"float32\")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_sequence_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_sequence_length, num_decoder_tokens), dtype=\"float32\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG3sYaeE0rP-"
      },
      "source": [
        "TEST code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6npgl-EtCnN"
      },
      "source": [
        "li = [\"i am having best day today\",\n",
        "  \"do you have any idea how it went\",\n",
        "  \"Well you deserve this\"]\n",
        "print(len(li))\n",
        "seq = max([len(txt) for txt in li])\n",
        "print(seq)\n",
        "token = set()\n",
        "for char in li:\n",
        "  if char not in token:\n",
        "    token.add(char)\n",
        "print(len(token))    \n",
        "arr = np.zeros((len(li),seq, len(token)))\n",
        "arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejCTsM_d1n__",
        "outputId": "1ace1ce0-56a0-42c0-f772-20161d1c273b"
      },
      "source": [
        "input_token_index[\"a\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9HwVVN8tk_0"
      },
      "source": [
        "### One-hot encoding of all the sentences of our dataset( converting words to number)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_tZr8t6SqVc"
      },
      "source": [
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "  for t, char in enumerate(input_text):\n",
        "    #wherever that character is present, convert it into 1.0\n",
        "    encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    #print(input_token_index)\n",
        "  encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "  for t, char in enumerate(target_text):\n",
        "    # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "    decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "    if t > 0:\n",
        "    # decoder_target_data will be ahead by one timestep\n",
        "    # and will not include the start character.\n",
        "      decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "  decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "  decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTwDaUmjDC4X"
      },
      "source": [
        "Now the matrix that we made encoder_input_data, decoder_target_data, decoder_inout_data is all filles with neccesary inputs. Now we give this matrix into the encoder layer and decoder layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuI2dfFIC74j"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDcjEzwIw_04"
      },
      "source": [
        "### Setting up encoder states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7egfcjHAC_Mu"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Input, Dense\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))   #shape of the inputs to be go on to lstm layer\n",
        "encoder = LSTM(latent_dim, return_state=True) #Adding lstm layer\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)  #the output of the encoder is the output and h(hidden_state) & c(cell_state)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "#Because the architecture of encoder does not output anything at this stage, We only maintain their hidden and cell state in the context vector,\n",
        "# later on, the decoder states will derive from this encoder states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wujeFN-RxFRU"
      },
      "source": [
        "### Setting up decoder states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHE6u9_Fw7gK"
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states) #this initial state is the context vector of encoder side\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8aQFN_c1Fow"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVenrO4_1E4m",
        "outputId": "8937cf53-35b3-4c71-e08e-999c62fd3ac3"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 54s 404ms/step - loss: 1.1399 - accuracy: 0.7351 - val_loss: 1.0989 - val_accuracy: 0.7140\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.8209 - accuracy: 0.7773 - val_loss: 0.8263 - val_accuracy: 0.7719\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.6553 - accuracy: 0.8148 - val_loss: 0.6963 - val_accuracy: 0.7990\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 49s 396ms/step - loss: 0.5727 - accuracy: 0.8339 - val_loss: 0.6326 - val_accuracy: 0.8156\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.5268 - accuracy: 0.8455 - val_loss: 0.5926 - val_accuracy: 0.8270\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.4916 - accuracy: 0.8554 - val_loss: 0.5592 - val_accuracy: 0.8361\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 49s 396ms/step - loss: 0.4636 - accuracy: 0.8629 - val_loss: 0.5383 - val_accuracy: 0.8410\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.4413 - accuracy: 0.8689 - val_loss: 0.5251 - val_accuracy: 0.8450\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 49s 392ms/step - loss: 0.4218 - accuracy: 0.8740 - val_loss: 0.5058 - val_accuracy: 0.8509\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 50s 396ms/step - loss: 0.4041 - accuracy: 0.8792 - val_loss: 0.4947 - val_accuracy: 0.8549\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.3875 - accuracy: 0.8839 - val_loss: 0.4870 - val_accuracy: 0.8574\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.3721 - accuracy: 0.8878 - val_loss: 0.4761 - val_accuracy: 0.8605\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.3570 - accuracy: 0.8929 - val_loss: 0.4687 - val_accuracy: 0.8628\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 51s 404ms/step - loss: 0.3437 - accuracy: 0.8965 - val_loss: 0.4683 - val_accuracy: 0.8628\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.3310 - accuracy: 0.9001 - val_loss: 0.4570 - val_accuracy: 0.8666\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.3185 - accuracy: 0.9042 - val_loss: 0.4585 - val_accuracy: 0.8668\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.3066 - accuracy: 0.9074 - val_loss: 0.4522 - val_accuracy: 0.8698\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 51s 404ms/step - loss: 0.2957 - accuracy: 0.9107 - val_loss: 0.4486 - val_accuracy: 0.8709\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.2851 - accuracy: 0.9138 - val_loss: 0.4496 - val_accuracy: 0.8712\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.2748 - accuracy: 0.9168 - val_loss: 0.4511 - val_accuracy: 0.8712\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.2654 - accuracy: 0.9198 - val_loss: 0.4537 - val_accuracy: 0.8721\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.2567 - accuracy: 0.9222 - val_loss: 0.4472 - val_accuracy: 0.8734\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.2478 - accuracy: 0.9248 - val_loss: 0.4534 - val_accuracy: 0.8721\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 51s 410ms/step - loss: 0.2393 - accuracy: 0.9274 - val_loss: 0.4511 - val_accuracy: 0.8742\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.2312 - accuracy: 0.9297 - val_loss: 0.4549 - val_accuracy: 0.8735\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.2241 - accuracy: 0.9319 - val_loss: 0.4553 - val_accuracy: 0.8751\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.2164 - accuracy: 0.9341 - val_loss: 0.4589 - val_accuracy: 0.8745\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.2092 - accuracy: 0.9365 - val_loss: 0.4640 - val_accuracy: 0.8739\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 52s 420ms/step - loss: 0.2029 - accuracy: 0.9379 - val_loss: 0.4734 - val_accuracy: 0.8730\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 56s 446ms/step - loss: 0.1964 - accuracy: 0.9402 - val_loss: 0.4703 - val_accuracy: 0.8743\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 54s 430ms/step - loss: 0.1903 - accuracy: 0.9419 - val_loss: 0.4720 - val_accuracy: 0.8745\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 53s 428ms/step - loss: 0.1845 - accuracy: 0.9438 - val_loss: 0.4789 - val_accuracy: 0.8745\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 52s 420ms/step - loss: 0.1789 - accuracy: 0.9455 - val_loss: 0.4850 - val_accuracy: 0.8734\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 51s 411ms/step - loss: 0.1737 - accuracy: 0.9469 - val_loss: 0.4856 - val_accuracy: 0.8737\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 51s 408ms/step - loss: 0.1686 - accuracy: 0.9483 - val_loss: 0.4869 - val_accuracy: 0.8749\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 51s 409ms/step - loss: 0.1638 - accuracy: 0.9500 - val_loss: 0.4989 - val_accuracy: 0.8733\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.1589 - accuracy: 0.9512 - val_loss: 0.4974 - val_accuracy: 0.8744\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.1545 - accuracy: 0.9527 - val_loss: 0.5046 - val_accuracy: 0.8736\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 49s 396ms/step - loss: 0.1502 - accuracy: 0.9540 - val_loss: 0.5139 - val_accuracy: 0.8728\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.1460 - accuracy: 0.9551 - val_loss: 0.5146 - val_accuracy: 0.8734\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.1422 - accuracy: 0.9562 - val_loss: 0.5224 - val_accuracy: 0.8727\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.1383 - accuracy: 0.9573 - val_loss: 0.5253 - val_accuracy: 0.8738\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.1347 - accuracy: 0.9586 - val_loss: 0.5296 - val_accuracy: 0.8726\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.1314 - accuracy: 0.9595 - val_loss: 0.5375 - val_accuracy: 0.8731\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 0.1279 - accuracy: 0.9607 - val_loss: 0.5425 - val_accuracy: 0.8734\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 50s 401ms/step - loss: 0.1250 - accuracy: 0.9612 - val_loss: 0.5402 - val_accuracy: 0.8732\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.1218 - accuracy: 0.9624 - val_loss: 0.5557 - val_accuracy: 0.8713\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 51s 412ms/step - loss: 0.1189 - accuracy: 0.9630 - val_loss: 0.5544 - val_accuracy: 0.8720\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 51s 411ms/step - loss: 0.1159 - accuracy: 0.9641 - val_loss: 0.5652 - val_accuracy: 0.8712\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.1134 - accuracy: 0.9647 - val_loss: 0.5697 - val_accuracy: 0.8719\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.1107 - accuracy: 0.9656 - val_loss: 0.5680 - val_accuracy: 0.8738\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 49s 390ms/step - loss: 0.1081 - accuracy: 0.9662 - val_loss: 0.5814 - val_accuracy: 0.8717\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 49s 395ms/step - loss: 0.1060 - accuracy: 0.9667 - val_loss: 0.5799 - val_accuracy: 0.8730\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.1033 - accuracy: 0.9678 - val_loss: 0.5826 - val_accuracy: 0.8729\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.1012 - accuracy: 0.9682 - val_loss: 0.5864 - val_accuracy: 0.8727\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.0994 - accuracy: 0.9685 - val_loss: 0.5967 - val_accuracy: 0.8723\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.0973 - accuracy: 0.9692 - val_loss: 0.5939 - val_accuracy: 0.8733\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.0949 - accuracy: 0.9700 - val_loss: 0.6041 - val_accuracy: 0.8718\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 49s 396ms/step - loss: 0.0930 - accuracy: 0.9705 - val_loss: 0.6070 - val_accuracy: 0.8720\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 49s 395ms/step - loss: 0.0912 - accuracy: 0.9712 - val_loss: 0.6148 - val_accuracy: 0.8723\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.0892 - accuracy: 0.9717 - val_loss: 0.6118 - val_accuracy: 0.8721\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.0874 - accuracy: 0.9722 - val_loss: 0.6227 - val_accuracy: 0.8717\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.0858 - accuracy: 0.9726 - val_loss: 0.6243 - val_accuracy: 0.8719\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.0840 - accuracy: 0.9730 - val_loss: 0.6246 - val_accuracy: 0.8727\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0826 - accuracy: 0.9734 - val_loss: 0.6292 - val_accuracy: 0.8723\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.0811 - accuracy: 0.9741 - val_loss: 0.6373 - val_accuracy: 0.8719\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 49s 392ms/step - loss: 0.0791 - accuracy: 0.9745 - val_loss: 0.6397 - val_accuracy: 0.8715\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.0778 - accuracy: 0.9747 - val_loss: 0.6450 - val_accuracy: 0.8724\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.0763 - accuracy: 0.9753 - val_loss: 0.6473 - val_accuracy: 0.8717\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.0748 - accuracy: 0.9755 - val_loss: 0.6512 - val_accuracy: 0.8718\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0740 - accuracy: 0.9759 - val_loss: 0.6576 - val_accuracy: 0.8723\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.0725 - accuracy: 0.9761 - val_loss: 0.6640 - val_accuracy: 0.8718\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0712 - accuracy: 0.9767 - val_loss: 0.6642 - val_accuracy: 0.8718\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 51s 412ms/step - loss: 0.0700 - accuracy: 0.9768 - val_loss: 0.6698 - val_accuracy: 0.8715\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 52s 416ms/step - loss: 0.0690 - accuracy: 0.9772 - val_loss: 0.6708 - val_accuracy: 0.8718\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 50s 403ms/step - loss: 0.0675 - accuracy: 0.9777 - val_loss: 0.6853 - val_accuracy: 0.8707\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 0.6831 - val_accuracy: 0.8718\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.0653 - accuracy: 0.9784 - val_loss: 0.6855 - val_accuracy: 0.8710\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.0642 - accuracy: 0.9786 - val_loss: 0.6889 - val_accuracy: 0.8708\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.0633 - accuracy: 0.9788 - val_loss: 0.6884 - val_accuracy: 0.8704\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 51s 405ms/step - loss: 0.0625 - accuracy: 0.9789 - val_loss: 0.6894 - val_accuracy: 0.8712\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.0614 - accuracy: 0.9793 - val_loss: 0.7043 - val_accuracy: 0.8703\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.0603 - accuracy: 0.9798 - val_loss: 0.7011 - val_accuracy: 0.8710\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0592 - accuracy: 0.9799 - val_loss: 0.7122 - val_accuracy: 0.8699\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.0584 - accuracy: 0.9802 - val_loss: 0.7124 - val_accuracy: 0.8708\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 50s 397ms/step - loss: 0.0577 - accuracy: 0.9805 - val_loss: 0.7170 - val_accuracy: 0.8699\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 49s 395ms/step - loss: 0.0567 - accuracy: 0.9807 - val_loss: 0.7230 - val_accuracy: 0.8695\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 50s 404ms/step - loss: 0.0561 - accuracy: 0.9807 - val_loss: 0.7170 - val_accuracy: 0.8711\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 49s 396ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.7196 - val_accuracy: 0.8705\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 49s 390ms/step - loss: 0.0540 - accuracy: 0.9813 - val_loss: 0.7293 - val_accuracy: 0.8697\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.0537 - accuracy: 0.9815 - val_loss: 0.7354 - val_accuracy: 0.8700\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 50s 399ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.7359 - val_accuracy: 0.8709\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 50s 400ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.7362 - val_accuracy: 0.8703\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 50s 402ms/step - loss: 0.0514 - accuracy: 0.9822 - val_loss: 0.7374 - val_accuracy: 0.8703\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 49s 394ms/step - loss: 0.0507 - accuracy: 0.9823 - val_loss: 0.7452 - val_accuracy: 0.8699\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 50s 398ms/step - loss: 0.0501 - accuracy: 0.9825 - val_loss: 0.7422 - val_accuracy: 0.8704\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 49s 392ms/step - loss: 0.0494 - accuracy: 0.9828 - val_loss: 0.7504 - val_accuracy: 0.8695\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 49s 391ms/step - loss: 0.0488 - accuracy: 0.9827 - val_loss: 0.7478 - val_accuracy: 0.8703\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 49s 392ms/step - loss: 0.0483 - accuracy: 0.9829 - val_loss: 0.7536 - val_accuracy: 0.8702\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 48s 388ms/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 0.7607 - val_accuracy: 0.8696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fdde66f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t-KmqBvTxNg",
        "outputId": "08fe9524-4d21-435a-8690-95ffe97e38f0"
      },
      "source": [
        "# Save model\n",
        "model.save(\"s2s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2I7uWwYUHRq"
      },
      "source": [
        "### Run inference (sampling)\n",
        "- encode input and retrieve initial decoder state\n",
        "- run one step of decoder with this initial state and a \"start of         sequence\" token as target. Output will be the next target token.\n",
        "- Repeat with the current target token and current states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBcWY_aRUBSu"
      },
      "source": [
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"s2s\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT2gsKHGaRAQ"
      },
      "source": [
        "decoder_inputs = model.input[1] #input_2\n",
        "decoder_state_input_h = Input(shape=(latent_dim,),name='input3')\n",
        "decoder_state_input_c = Input(shape=(latent_dim,),name='input4')\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs=decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4klF52ihy-A"
      },
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJimUS6SjCsI"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_sequence_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DaXYZowjMAb",
        "outputId": "faf67d5a-5e26-4a03-870e-296ecbb80e69"
      },
      "source": [
        "for seq_index in range(20):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    #input_seq = input(\"Enter your Text: \")\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"English sentence:\", input_texts[seq_index])\n",
        "    print(\"French sentence:\", decoded_sentence)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "English sentence: Go.\n",
            "French sentence: Bouge !\n",
            "\n",
            "-\n",
            "English sentence: Go.\n",
            "French sentence: Bouge !\n",
            "\n",
            "-\n",
            "English sentence: Go.\n",
            "French sentence: Bouge !\n",
            "\n",
            "-\n",
            "English sentence: Hi.\n",
            "French sentence: Salut.\n",
            "\n",
            "-\n",
            "English sentence: Hi.\n",
            "French sentence: Salut.\n",
            "\n",
            "-\n",
            "English sentence: Run!\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run!\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run!\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run!\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run!\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run!\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run!\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run!\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run.\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run.\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run.\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run.\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run.\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run.\n",
            "French sentence: Fuyons !\n",
            "\n",
            "-\n",
            "English sentence: Run.\n",
            "French sentence: Fuyons !\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TdUHBxnfTgv"
      },
      "source": [
        "### Test code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXO73cVPUWzd",
        "outputId": "a822d19a-e070-4592-de94-494f97625666"
      },
      "source": [
        "a = [\"hi\", \"how\", \"are\", \"you\"]\n",
        "#french\n",
        "b=[\"salut\",\"comment\" , \"ça\", \"va\"]\n",
        "c = []\n",
        "for i, (x, y) in enumerate(zip(a, b)):\n",
        "  print(i, (x, y))\n",
        "  for t, char in enumerate(a):\n",
        "    print(t, char)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 ('hi', 'salut')\n",
            "0 hi\n",
            "1 how\n",
            "2 are\n",
            "3 you\n",
            "1 ('how', 'comment')\n",
            "0 hi\n",
            "1 how\n",
            "2 are\n",
            "3 you\n",
            "2 ('are', 'ça')\n",
            "0 hi\n",
            "1 how\n",
            "2 are\n",
            "3 you\n",
            "3 ('you', 'va')\n",
            "0 hi\n",
            "1 how\n",
            "2 are\n",
            "3 you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNQtG-EsbMpG"
      },
      "source": [
        "##Test code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdnzT_OWClR7"
      },
      "source": [
        "para = 'i am recognizing the pattern in my behaviour. \\thu mari swabhav ne odkhu chu. \\tCC-BY 2.0 (France) Attribution: tatoeba.org #5828662 (CK) & #4678647 (sacredceltic)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8SxigouSwkB",
        "outputId": "4f57505a-6f14-4b29-b395-fadddd0adf4e"
      },
      "source": [
        "sampl = 150\n",
        "inp = []\n",
        "out= []\n",
        "input_char = set()\n",
        "output_char = set()\n",
        "for i in para[: min(sampl, len(para) - 1)]:\n",
        "  input_tex, target_tex, _ = para.split(\"\\t\")\n",
        "  target_tex = \"/t\" + target_tex + \"\\n\"\n",
        "  inp.append(input_tex)\n",
        "  out.append(target_tex)\n",
        "  for char in input_tex:\n",
        "    if char not in input_char:\n",
        "      input_char.add(char)\n",
        "  for char in target_tex:\n",
        "    if char not in output_char:\n",
        "      output_char.add(char)  \n",
        "      #Now we have a single set of characters stored in input_char and output_char \n",
        "\n",
        "input_char = sorted(list(input_char)) \n",
        "output_char = sorted(list(output_char))\n",
        "max_encoder_seq_length = max([len(txt) for txt in inp])\n",
        "print(max_encoder_seq_length)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFoBP_eNTGNM",
        "outputId": "32f76790-973c-478d-cc35-ddee0ae953fa"
      },
      "source": [
        "len(inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cfYciKQVLPA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}